{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from generate_synthetic import generate_synthetic, train_val_dataloader\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "config['local_batch_size'] = 10\n",
    "config['local_iters'] = 1           # E\n",
    "config['global_iters'] = 200         # T\n",
    "\n",
    "config['num_devices'] = 30           # p\n",
    "config['num_active_devices'] = 10\n",
    "\n",
    "config['lr'] = 0.01\n",
    "config['num_classes'] = 10\n",
    "config['device'] = 'cuda:0'\n",
    "\n",
    "config['iid'] = 0\n",
    "config['alpha'] = 0.5\n",
    "config['beta'] = 0.75\n",
    "\n",
    "config['gamma'] = 0.5\n",
    "config['dimension'] = 60\n",
    "\n",
    "config_path = '../config/synthetic_iid.yaml' \n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.75, 'beta': 0.75, 'device': 'cuda:0', 'dimension': 60, 'gamma': 0.5, 'global_iters': 200, 'iid': 0, 'local_batch_size': 10, 'local_iters': 1, 'lr': 0.01, 'num_active_devices': 10, 'num_classes': 10, 'num_devices': 30}\n"
     ]
    }
   ],
   "source": [
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer_hidden = nn.Linear(dim_in, dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_hidden(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "device = torch.device(config['device'])\n",
    "    \n",
    "global_model = MLP(dim_in=config['dimension'], dim_out=config['num_classes']).to(device)\n",
    "global_optim = torch.optim.SGD(global_model.parameters(), lr=config['lr'], weight_decay=1e-4)\n",
    "\n",
    "local_model_list = []\n",
    "local_optim_list = []\n",
    "for local_id in range(config['num_devices']:\n",
    "    local_model = MLP(dim_in=config['dimension'], dim_out=config['num_classes']).to(device)\n",
    "    local_optim = torch.optim.SGD(local_model.parameters(), lr=config['lr'], weight_decay=1e-4)\n",
    "    local_model_list.append(local_model)\n",
    "    local_optim_list.append(local_optim)\n",
    "    \n",
    "global_init_weight = copy.deepcopy(global_model.state_dict())\n",
    "local_model_init_weight_list = []\n",
    "for local_id in range(config['num_devices']):\n",
    "    local_weight = copy.deepcopy(local_model_list[local_id].state_dict())\n",
    "    local_model_init_weight_list.append(local_weight)\n",
    "\n",
    "criterion = nn.NLLLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th users has 1909 exampls\n",
      "1-th users has 171 exampls\n",
      "2-th users has 436 exampls\n",
      "3-th users has 4876 exampls\n",
      "4-th users has 2337 exampls\n",
      "5-th users has 57 exampls\n",
      "6-th users has 415 exampls\n",
      "7-th users has 90 exampls\n",
      "8-th users has 94 exampls\n",
      "9-th users has 174 exampls\n",
      "10-th users has 122 exampls\n",
      "11-th users has 1050 exampls\n",
      "12-th users has 300 exampls\n",
      "13-th users has 119 exampls\n",
      "14-th users has 182 exampls\n",
      "15-th users has 156 exampls\n",
      "16-th users has 1133 exampls\n",
      "17-th users has 86 exampls\n",
      "18-th users has 152 exampls\n",
      "19-th users has 59 exampls\n",
      "20-th users has 50 exampls\n",
      "21-th users has 251 exampls\n",
      "22-th users has 357 exampls\n",
      "23-th users has 62 exampls\n",
      "24-th users has 5162 exampls\n",
      "25-th users has 52 exampls\n",
      "26-th users has 109 exampls\n",
      "27-th users has 87 exampls\n",
      "28-th users has 1220 exampls\n",
      "29-th users has 1081 exampls\n"
     ]
    }
   ],
   "source": [
    "# generate training data\n",
    "X_split, y_split, weight_per_user = generate_synthetic(alpha=config['alpha'], beta=config['beta'], iid=config['iid'], \n",
    "                                      num_user=config['num_devices'], dimension=config['dimension'],\n",
    "                                      num_class=config['num_classes'])\n",
    "\n",
    "trainloader_list, validloader_list = [], []\n",
    "trainloader_iterator_list, validloader_iterator_list = [], []\n",
    "for local_id in range(config['num_devices']):\n",
    "    trainloader, validloader = train_val_dataloader(X_split, y_split, local_id, batch_size=config['local_batch_size'])\n",
    "    trainloader_list.append(trainloader)\n",
    "    validloader_list.append(validloader)\n",
    "    \n",
    "    trainloader_iterator_list.append(iter(trainloader_list[local_id]))\n",
    "    validloader_iterator_list.append(iter(validloader_list[local_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, dataloader):\n",
    "    \"\"\" Returns the inference accuracy and loss.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    total, correct = 0.0, 0.0\n",
    "    loss = list()\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Inference\n",
    "        outputs = model(images)\n",
    "        batch_loss = criterion(outputs, labels)\n",
    "        loss += [batch_loss.item()]\n",
    "\n",
    "        # Prediction\n",
    "        _, pred_labels = torch.max(outputs, 1)\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "        correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "        total += len(labels)\n",
    "\n",
    "    accuracy = correct/total\n",
    "    loss = sum(loss)/len(loss)\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_state_dicts(w, weight):\n",
    "    \"\"\"\n",
    "    Returns the average of the weights or gradients.\n",
    "    \"\"\"\n",
    "    weight = weight/sum(weight)\n",
    "    \n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for key in w_avg.keys():\n",
    "        w_avg[key] = torch.zeros_like(w_avg[key])\n",
    "        for i in range(len(w)):\n",
    "            w_avg[key] = w_avg[key] + w[i][key]*weight[i]\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global 1, acc 0.118050, loss 2.462530\n"
     ]
    }
   ],
   "source": [
    "# load initial value\n",
    "global_model.load_state_dict(global_init_weight)\n",
    "for local_id in range(config['num_devices']):\n",
    "    local_model_list[local_id].load_state_dict(local_model_init_weight_list[local_id])\n",
    "\n",
    "# start training\n",
    "global_acc = []\n",
    "global_loss = []\n",
    "    \n",
    "# test global model\n",
    "list_acc, list_loss = [], [] \n",
    "for local_id in range(config['num_devices']):\n",
    "    acc, loss = inference(global_model, validloader_list[local_id])\n",
    "    list_acc.append(acc)\n",
    "    list_loss.append(loss)\n",
    "global_acc +=  [sum(list_acc)/len(list_acc)]\n",
    "global_loss += [sum(list_loss)/len(list_loss)]\n",
    "print('global %d, acc %f, loss %f'%(len(global_acc), global_acc[-1], global_loss[-1]))\n",
    "    \n",
    "for global_iters in range(config['global_iters']*config['local_iters']):\n",
    "    \n",
    "    activate_devices = np.arange(config['num_devices'])\n",
    "    \n",
    "    # get the local grad for each device\n",
    "    for local_id in activate_devices:\n",
    "        # load single mini-batch\n",
    "        try:\n",
    "            inputs, labels = next(trainloader_iterator_list[local_id])\n",
    "        except StopIteration:\n",
    "            trainloader_iterator_list[local_id] = iter(trainloader_list[local_id])\n",
    "            inputs, labels = next(trainloader_iterator_list[local_id])\n",
    "    \n",
    "        # train local model\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        local_model_list[local_id].train()\n",
    "        local_model_list[local_id].zero_grad()\n",
    "        log_probs = local_model_list[local_id](inputs)\n",
    "        loss = criterion(log_probs, labels)\n",
    "        loss.backward()\n",
    "        local_optim_list[local_id].step()\n",
    "        \n",
    "    # update local weight\n",
    "    for local_id in activate_devices:\n",
    "        local_weight = copy.deepcopy(local_model_list[local_id].state_dict())\n",
    "        local_grad = local_grad_list[local_id]\n",
    "        for key in local_weight.keys():\n",
    "            local_weight[key] = local_weight[key] - config['lr'] * local_grad[key]\n",
    "        local_model_list[local_id].load_state_dict(local_weight)\n",
    "\n",
    "    # average local models \n",
    "    if global_iters % config['local_iters'] == 0:\n",
    "        local_weight_list = [local_model.state_dict() for local_model in local_model_list]\n",
    "        avg_local_weight = average_state_dicts(local_weight_list, weight_per_user)\n",
    "        global_model.load_state_dict(avg_local_weight)\n",
    "        for local_id in range(config['num_devices']):\n",
    "            local_model_list[local_id].load_state_dict(avg_local_weight)\n",
    "        \n",
    "    # test global model\n",
    "    if global_iters % config['local_iters'] == 0:\n",
    "        list_acc, list_loss = [], [] \n",
    "        for local_id in range(config['num_devices']):\n",
    "            acc, loss = inference(global_model, validloader_list[local_id])\n",
    "            list_acc.append(acc)\n",
    "            list_loss.append(loss)\n",
    "        global_acc +=  [sum(list_acc)/len(list_acc)]\n",
    "        global_loss += [sum(list_loss)/len(list_loss)]\n",
    "        # print('global %d, acc %f, loss %f'%(len(global_acc), global_acc[-1], global_loss[-1]))\n",
    "    \n",
    "with open('fedavg_%.2f.pkl'%config['beta'], 'wb') as f:\n",
    "    pickle.dump([global_acc, global_loss], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, axs = plt.subplots()\n",
    "\n",
    "# # draw couple fl\n",
    "# with open('couple_fl.pkl', 'rb') as f:\n",
    "#     global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "# y = global_acc\n",
    "# x = np.arange(len(y))\n",
    "# axs.plot(x,y,label='Couple FL')\n",
    "\n",
    "# # draw fedavg\n",
    "# with open('fedavg.pkl', 'rb') as f:\n",
    "#     global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "# y = global_acc\n",
    "# x = np.arange(len(y))\n",
    "# axs.plot(x,y,label='FedAvg')\n",
    "    \n",
    "# axs.set_xlabel('Communication round')\n",
    "# axs.set_ylabel('Global model accuracy')\n",
    "# axs.grid(True)\n",
    "\n",
    "# plt.title('Synthetic dataset - Accuracy / Communication round')\n",
    "# fig.tight_layout()\n",
    "# plt.legend()\n",
    "# plt.savefig('couple_fl_vs_fedavf.pdf')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "\n",
    "# diversity 0\n",
    "with open('fedavg_0.00.pkl', 'rb') as f:\n",
    "    global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "y = global_acc\n",
    "x = np.arange(len(y))\n",
    "axs.plot(x,y,label='Diversity 0')\n",
    "\n",
    "# diversity 0.25\n",
    "with open('fedavg_0.25.pkl', 'rb') as f:\n",
    "    global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "y = global_acc\n",
    "x = np.arange(len(y))\n",
    "axs.plot(x,y,label='Diversity 0.25')\n",
    "\n",
    "# diversity 0.5\n",
    "with open('fedavg_0.50.pkl', 'rb') as f:\n",
    "    global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "y = global_acc\n",
    "x = np.arange(len(y))\n",
    "axs.plot(x,y,label='Diversity 0.5')\n",
    "\n",
    "# diversity 0.75\n",
    "with open('fedavg_0.75.pkl', 'rb') as f:\n",
    "    global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "y = global_acc\n",
    "x = np.arange(len(y))\n",
    "axs.plot(x,y,label='Diversity 0.75')\n",
    "\n",
    "# diversity 1\n",
    "with open('fedavg_1.00.pkl', 'rb') as f:\n",
    "    global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "y = global_acc\n",
    "x = np.arange(len(y))\n",
    "axs.plot(x,y,label='Diversity 1')\n",
    "    \n",
    "axs.set_xlabel('Communication round')\n",
    "axs.set_ylabel('Global model accuracy')\n",
    "axs.grid(True)\n",
    "\n",
    "plt.title('Synthetic dataset - Accuracy / Communication round')\n",
    "fig.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('fedavg_diff_diversity.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
