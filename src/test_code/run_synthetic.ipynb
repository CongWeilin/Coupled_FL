{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from generate_synthetic import generate_synthetic, train_val_dataloader\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "config['local_batch_size'] = 10\n",
    "config['local_iters'] = 1           # E\n",
    "config['global_iters'] = 200         # T\n",
    "\n",
    "config['num_devices'] = 30           # p\n",
    "config['num_active_devices'] = 10\n",
    "\n",
    "config['lr'] = 0.01\n",
    "config['num_classes'] = 10\n",
    "config['device'] = 'cuda:0'\n",
    "\n",
    "config['iid'] = 0\n",
    "config['alpha'] = 0.5\n",
    "config['beta'] = 0.75\n",
    "\n",
    "config['gamma'] = 0.5\n",
    "config['dimension'] = 60\n",
    "\n",
    "config_path = '../config/synthetic_iid.yaml' \n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.75, 'beta': 0.75, 'device': 'cuda:0', 'dimension': 60, 'gamma': 0.5, 'global_iters': 200, 'iid': 0, 'local_batch_size': 10, 'local_iters': 1, 'lr': 0.01, 'num_active_devices': 10, 'num_classes': 10, 'num_devices': 30}\n"
     ]
    }
   ],
   "source": [
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer_hidden = nn.Linear(dim_in, dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_hidden(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "device = torch.device(config['device'])\n",
    "    \n",
    "global_model = MLP(dim_in=config['dimension'], dim_out=config['num_classes']).to(device)\n",
    "local_model_list = [\n",
    "    MLP(dim_in=config['dimension'], dim_out=config['num_classes']).to(device)\n",
    "    for _ in range(config['num_devices'])\n",
    "]\n",
    "\n",
    "global_init_weight = copy.deepcopy(global_model.state_dict())\n",
    "local_model_init_weight_list = []\n",
    "for local_id in range(config['num_devices']):\n",
    "    local_weight = copy.deepcopy(local_model_list[local_id].state_dict())\n",
    "    local_model_init_weight_list.append(local_weight)\n",
    "\n",
    "criterion = nn.NLLLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th users has 1909 exampls\n",
      "1-th users has 171 exampls\n",
      "2-th users has 436 exampls\n",
      "3-th users has 4876 exampls\n",
      "4-th users has 2337 exampls\n",
      "5-th users has 57 exampls\n",
      "6-th users has 415 exampls\n",
      "7-th users has 90 exampls\n",
      "8-th users has 94 exampls\n",
      "9-th users has 174 exampls\n",
      "10-th users has 122 exampls\n",
      "11-th users has 1050 exampls\n",
      "12-th users has 300 exampls\n",
      "13-th users has 119 exampls\n",
      "14-th users has 182 exampls\n",
      "15-th users has 156 exampls\n",
      "16-th users has 1133 exampls\n",
      "17-th users has 86 exampls\n",
      "18-th users has 152 exampls\n",
      "19-th users has 59 exampls\n",
      "20-th users has 50 exampls\n",
      "21-th users has 251 exampls\n",
      "22-th users has 357 exampls\n",
      "23-th users has 62 exampls\n",
      "24-th users has 5162 exampls\n",
      "25-th users has 52 exampls\n",
      "26-th users has 109 exampls\n",
      "27-th users has 87 exampls\n",
      "28-th users has 1220 exampls\n",
      "29-th users has 1081 exampls\n"
     ]
    }
   ],
   "source": [
    "# generate training data\n",
    "X_split, y_split, weight_per_user = generate_synthetic(alpha=config['alpha'], beta=config['beta'], iid=config['iid'], \n",
    "                                      num_user=config['num_devices'], dimension=config['dimension'],\n",
    "                                      num_class=config['num_classes'])\n",
    "\n",
    "trainloader_list, validloader_list = [], []\n",
    "trainloader_iterator_list, validloader_iterator_list = [], []\n",
    "for local_id in range(config['num_devices']):\n",
    "    trainloader, validloader = train_val_dataloader(X_split, y_split, local_id, batch_size=config['local_batch_size'])\n",
    "    trainloader_list.append(trainloader)\n",
    "    validloader_list.append(validloader)\n",
    "    \n",
    "    trainloader_iterator_list.append(iter(trainloader_list[local_id]))\n",
    "    validloader_iterator_list.append(iter(validloader_list[local_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, dataloader):\n",
    "    \"\"\" Returns the inference accuracy and loss.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    total, correct = 0.0, 0.0\n",
    "    loss = list()\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Inference\n",
    "        outputs = model(images)\n",
    "        batch_loss = criterion(outputs, labels)\n",
    "        loss += [batch_loss.item()]\n",
    "\n",
    "        # Prediction\n",
    "        _, pred_labels = torch.max(outputs, 1)\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "        correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "        total += len(labels)\n",
    "\n",
    "    accuracy = correct/total\n",
    "    loss = sum(loss)/len(loss)\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_state_dicts(w, weight):\n",
    "    \"\"\"\n",
    "    Returns the average of the weights or gradients.\n",
    "    \"\"\"\n",
    "    weight = weight/sum(weight)\n",
    "    \n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for key in w_avg.keys():\n",
    "        w_avg[key] = torch.zeros_like(w_avg[key])\n",
    "        for i in range(len(w)):\n",
    "            w_avg[key] = w_avg[key] + w[i][key]*weight[i]\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coupled FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load initial value\n",
    "global_model.load_state_dict(global_init_weight)\n",
    "for local_id in range(config['num_devices']):\n",
    "    local_model_list[local_id].load_state_dict(local_model_init_weight_list[local_id])\n",
    "    \n",
    "# start training\n",
    "global_acc = []\n",
    "global_loss = []\n",
    "    \n",
    "# test global model\n",
    "list_acc, list_loss = [], [] \n",
    "for local_id in range(config['num_devices']):\n",
    "    acc, loss = inference(global_model, validloader_list[local_id])\n",
    "    list_acc.append(acc)\n",
    "    list_loss.append(loss)\n",
    "global_acc +=  [sum(list_acc)/len(list_acc)]\n",
    "global_loss += [sum(list_loss)/len(list_loss)]\n",
    "print('global %d, acc %f, loss %f'%(len(global_acc), global_acc[-1], global_loss[-1]))\n",
    "    \n",
    "for global_iters in range(config['global_iters']):\n",
    "    \n",
    "    activate_devices = np.arange(config['num_devices'])\n",
    "    \n",
    "    # get the local grad for each device\n",
    "    local_grad_list = []\n",
    "    for local_id in activate_devices:\n",
    "        # load single mini-batch\n",
    "        try:\n",
    "            inputs, labels = next(trainloader_iterator_list[local_id])\n",
    "        except StopIteration:\n",
    "            trainloader_iterator_list[local_id] = iter(trainloader_list[local_id])\n",
    "            inputs, labels = next(trainloader_iterator_list[local_id])\n",
    "    \n",
    "        # train local model\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        local_model_list[local_id].train()\n",
    "        local_model_list[local_id].zero_grad()\n",
    "        log_probs = local_model_list[local_id](inputs)\n",
    "        loss = criterion(log_probs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        local_grads = dict()\n",
    "        for key, val in local_model_list[local_id].named_parameters():\n",
    "            local_grads[key] = val.grad.data.detach()\n",
    "        \n",
    "        local_grad_list.append(local_grads)\n",
    "        \n",
    "    # average local grads\n",
    "    if global_iters % config['local_iters'] == 0:\n",
    "        avg_local_grad = average_state_dicts(local_grad_list, weight_per_user[activate_devices])\n",
    "        \n",
    "    # update local weight\n",
    "    for local_id in activate_devices:\n",
    "        local_weight = copy.deepcopy(local_model_list[local_id].state_dict())\n",
    "        local_grad = local_grad_list[local_id]\n",
    "        for key in local_weight.keys():\n",
    "            local_weight[key] = local_weight[key] - config['lr'] * (avg_local_grad[key] * config['gamma'] + local_grad[key] * (1-config['gamma']))\n",
    "        local_model_list[local_id].load_state_dict(local_weight)\n",
    "\n",
    "    # average local models \n",
    "    if global_iters % config['local_iters'] == 0:\n",
    "        local_weight_list = [local_model.state_dict() for local_model in local_model_list]\n",
    "        avg_local_weight = average_state_dicts(local_weight_list, weight_per_user)\n",
    "        global_model.load_state_dict(avg_local_weight)\n",
    "        for local_id in range(config['num_devices']):\n",
    "            local_model_list[local_id].load_state_dict(avg_local_weight)\n",
    "        \n",
    "    # test global model\n",
    "    if global_iters % config['local_iters'] == 0:\n",
    "        list_acc, list_loss = [], [] \n",
    "        for local_id in range(config['num_devices']):\n",
    "            acc, loss = inference(global_model, validloader_list[local_id])\n",
    "            list_acc.append(acc)\n",
    "            list_loss.append(loss)\n",
    "        global_acc +=  [sum(list_acc)/len(list_acc)]\n",
    "        global_loss += [sum(list_loss)/len(list_loss)]\n",
    "        # print('global %d, acc %f, loss %f'%(len(global_acc), global_acc[-1], global_loss[-1]))\n",
    "\n",
    "with open('couple_fl.pkl', 'wb') as f:\n",
    "    pickle.dump([global_acc, global_loss], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global 1, acc 0.118050, loss 2.462530\n"
     ]
    }
   ],
   "source": [
    "# load initial value\n",
    "global_model.load_state_dict(global_init_weight)\n",
    "for local_id in range(config['num_devices']):\n",
    "    local_model_list[local_id].load_state_dict(local_model_init_weight_list[local_id])\n",
    "\n",
    "# start training\n",
    "global_acc = []\n",
    "global_loss = []\n",
    "    \n",
    "# test global model\n",
    "list_acc, list_loss = [], [] \n",
    "for local_id in range(config['num_devices']):\n",
    "    acc, loss = inference(global_model, validloader_list[local_id])\n",
    "    list_acc.append(acc)\n",
    "    list_loss.append(loss)\n",
    "global_acc +=  [sum(list_acc)/len(list_acc)]\n",
    "global_loss += [sum(list_loss)/len(list_loss)]\n",
    "print('global %d, acc %f, loss %f'%(len(global_acc), global_acc[-1], global_loss[-1]))\n",
    "    \n",
    "for global_iters in range(config['global_iters']*config['local_iters']):\n",
    "    \n",
    "    activate_devices = np.arange(config['num_devices'])\n",
    "    \n",
    "    # get the local grad for each device\n",
    "    local_grad_list = []\n",
    "    for local_id in activate_devices:\n",
    "        # load single mini-batch\n",
    "        try:\n",
    "            inputs, labels = next(trainloader_iterator_list[local_id])\n",
    "        except StopIteration:\n",
    "            trainloader_iterator_list[local_id] = iter(trainloader_list[local_id])\n",
    "            inputs, labels = next(trainloader_iterator_list[local_id])\n",
    "    \n",
    "        # train local model\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        local_model_list[local_id].train()\n",
    "        local_model_list[local_id].zero_grad()\n",
    "        log_probs = local_model_list[local_id](inputs)\n",
    "        loss = criterion(log_probs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        local_grads = dict()\n",
    "        for key, val in local_model_list[local_id].named_parameters():\n",
    "            local_grads[key] = val.grad.data.detach()\n",
    "        \n",
    "        local_grad_list.append(local_grads)\n",
    "        \n",
    "    # update local weight\n",
    "    for local_id in activate_devices:\n",
    "        local_weight = copy.deepcopy(local_model_list[local_id].state_dict())\n",
    "        local_grad = local_grad_list[local_id]\n",
    "        for key in local_weight.keys():\n",
    "            local_weight[key] = local_weight[key] - config['lr'] * local_grad[key]\n",
    "        local_model_list[local_id].load_state_dict(local_weight)\n",
    "\n",
    "    # average local models \n",
    "    if global_iters % config['local_iters'] == 0:\n",
    "        local_weight_list = [local_model.state_dict() for local_model in local_model_list]\n",
    "        avg_local_weight = average_state_dicts(local_weight_list, weight_per_user)\n",
    "        global_model.load_state_dict(avg_local_weight)\n",
    "        for local_id in range(config['num_devices']):\n",
    "            local_model_list[local_id].load_state_dict(avg_local_weight)\n",
    "        \n",
    "    # test global model\n",
    "    if global_iters % config['local_iters'] == 0:\n",
    "        list_acc, list_loss = [], [] \n",
    "        for local_id in range(config['num_devices']):\n",
    "            acc, loss = inference(global_model, validloader_list[local_id])\n",
    "            list_acc.append(acc)\n",
    "            list_loss.append(loss)\n",
    "        global_acc +=  [sum(list_acc)/len(list_acc)]\n",
    "        global_loss += [sum(list_loss)/len(list_loss)]\n",
    "        # print('global %d, acc %f, loss %f'%(len(global_acc), global_acc[-1], global_loss[-1]))\n",
    "    \n",
    "with open('fedavg_%.2f.pkl'%config['beta'], 'wb') as f:\n",
    "    pickle.dump([global_acc, global_loss], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, axs = plt.subplots()\n",
    "\n",
    "# # draw couple fl\n",
    "# with open('couple_fl.pkl', 'rb') as f:\n",
    "#     global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "# y = global_acc\n",
    "# x = np.arange(len(y))\n",
    "# axs.plot(x,y,label='Couple FL')\n",
    "\n",
    "# # draw fedavg\n",
    "# with open('fedavg.pkl', 'rb') as f:\n",
    "#     global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "# y = global_acc\n",
    "# x = np.arange(len(y))\n",
    "# axs.plot(x,y,label='FedAvg')\n",
    "    \n",
    "# axs.set_xlabel('Communication round')\n",
    "# axs.set_ylabel('Global model accuracy')\n",
    "# axs.grid(True)\n",
    "\n",
    "# plt.title('Synthetic dataset - Accuracy / Communication round')\n",
    "# fig.tight_layout()\n",
    "# plt.legend()\n",
    "# plt.savefig('couple_fl_vs_fedavf.pdf')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "\n",
    "# diversity 0\n",
    "with open('fedavg_0.00.pkl', 'rb') as f:\n",
    "    global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "y = global_acc\n",
    "x = np.arange(len(y))\n",
    "axs.plot(x,y,label='Diversity 0')\n",
    "\n",
    "# diversity 0.25\n",
    "with open('fedavg_0.25.pkl', 'rb') as f:\n",
    "    global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "y = global_acc\n",
    "x = np.arange(len(y))\n",
    "axs.plot(x,y,label='Diversity 0.25')\n",
    "\n",
    "# diversity 0.5\n",
    "with open('fedavg_0.50.pkl', 'rb') as f:\n",
    "    global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "y = global_acc\n",
    "x = np.arange(len(y))\n",
    "axs.plot(x,y,label='Diversity 0.5')\n",
    "\n",
    "# diversity 0.75\n",
    "with open('fedavg_0.75.pkl', 'rb') as f:\n",
    "    global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "y = global_acc\n",
    "x = np.arange(len(y))\n",
    "axs.plot(x,y,label='Diversity 0.75')\n",
    "\n",
    "# diversity 1\n",
    "with open('fedavg_1.00.pkl', 'rb') as f:\n",
    "    global_acc, global_loss = pickle.load(f)\n",
    "    \n",
    "y = global_acc\n",
    "x = np.arange(len(y))\n",
    "axs.plot(x,y,label='Diversity 1')\n",
    "    \n",
    "axs.set_xlabel('Communication round')\n",
    "axs.set_ylabel('Global model accuracy')\n",
    "axs.grid(True)\n",
    "\n",
    "plt.title('Synthetic dataset - Accuracy / Communication round')\n",
    "fig.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('fedavg_diff_diversity.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "\n",
    "\"\"\"\n",
    "Coupled_FL\n",
    "\"\"\"\n",
    "# diversity 0\n",
    "with open('../coupled_0.00.pkl', 'rb') as f:\n",
    "    global_acc, global_loss, local_acc, local_loss = pickle.load(f)\n",
    "\n",
    "# y = local_acc\n",
    "# x = np.arange(len(y))\n",
    "# axs.plot(x,y,label='Diversity 0 (Coupled_FL)', linestyle='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(local_acc), step=5)\n",
    "y = [local_acc[i] for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [local_acc[i] for i in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8593673772559421,\n",
       " 0.9002571284924226,\n",
       " 0.8764298642533938,\n",
       " 0.9212747790751756,\n",
       " 0.8477434717387211,\n",
       " 0.8210246072010777,\n",
       " 0.8247090643196717,\n",
       " 0.8349507633577776,\n",
       " 0.8354799448917095,\n",
       " 0.8302937694114163,\n",
       " 0.8446414488414398,\n",
       " 0.8690529579353109,\n",
       " 0.8512957855361435,\n",
       " 0.8380818980292866,\n",
       " 0.8596983853689645,\n",
       " 0.8573887599636768,\n",
       " 0.8025497378438555,\n",
       " 0.8652922220753103,\n",
       " 0.8982947902767213,\n",
       " 0.8375867269984918,\n",
       " 0.8613081155081064,\n",
       " 0.8306917918682626,\n",
       " 0.8438656442593399,\n",
       " 0.885344745154956,\n",
       " 0.8373887762001353,\n",
       " 0.8134684168264219,\n",
       " 0.8180655867949895,\n",
       " 0.7859316125484319,\n",
       " 0.8211954559601619,\n",
       " 0.8008853813794898,\n",
       " 0.7770956326117258,\n",
       " 0.8382804588149344,\n",
       " 0.8743819203109263,\n",
       " 0.8004883151415859,\n",
       " 0.8332063847408604,\n",
       " 0.7570189853719265,\n",
       " 0.8772148506085463,\n",
       " 0.8058270237387883,\n",
       " 0.7871870731517701,\n",
       " 0.8137930685666536,\n",
       " 0.8130544244026151,\n",
       " 0.8238590343480048,\n",
       " 0.8159490291843234,\n",
       " 0.8323317205670147,\n",
       " 0.888599392029539,\n",
       " 0.7729330576158071,\n",
       " 0.8062389020981222,\n",
       " 0.8643563706861789,\n",
       " 0.7939894283964426,\n",
       " 0.8213115947233594,\n",
       " 0.873892714527603,\n",
       " 0.7684985248283331,\n",
       " 0.8031001329824858,\n",
       " 0.8047448776150601,\n",
       " 0.8150777103486953,\n",
       " 0.7518400205459029,\n",
       " 0.7871561836855955,\n",
       " 0.7641799523442525,\n",
       " 0.7213900095465023,\n",
       " 0.7335353106629466,\n",
       " 0.7578372477196006,\n",
       " 0.7798624475783189,\n",
       " 0.7920890084754589,\n",
       " 0.858434400987333,\n",
       " 0.7701370344778053,\n",
       " 0.7091764692048403,\n",
       " 0.856023591445345,\n",
       " 0.7477881905113143,\n",
       " 0.6902525644415259,\n",
       " 0.7390592169321742,\n",
       " 0.8204005124777183,\n",
       " 0.8388024132730015,\n",
       " 0.8423722662141779,\n",
       " 0.8298057040998218,\n",
       " 0.8318449197860962,\n",
       " 0.7458922184168797,\n",
       " 0.7737297918709591,\n",
       " 0.6867087630506747,\n",
       " 0.721047658285727,\n",
       " 0.7155376604729454,\n",
       " 0.7199089635854342,\n",
       " 0.7190533486121721,\n",
       " 0.6942494270435448,\n",
       " 0.8020647000058766,\n",
       " 0.7374015281540637,\n",
       " 0.8046162191691512,\n",
       " 0.8028770005193089,\n",
       " 0.8351427494074551,\n",
       " 0.715296890473361,\n",
       " 0.7141313555822792,\n",
       " 0.77743628291797,\n",
       " 0.737107410507005,\n",
       " 0.6943136446213941,\n",
       " 0.767765951789472,\n",
       " 0.8198772485809158,\n",
       " 0.7837720380797877,\n",
       " 0.726967787114846,\n",
       " 0.5945900072150072,\n",
       " 0.800716628959276,\n",
       " 0.6520726205901369,\n",
       " 0.7758317760872608,\n",
       " 0.8526939577050564,\n",
       " 0.665278259266089,\n",
       " 0.7364085309551842,\n",
       " 0.7284553613440314,\n",
       " 0.6208448698709519,\n",
       " 0.6895737970616266,\n",
       " 0.7693729739086647,\n",
       " 0.7883974444797883,\n",
       " 0.6972061096708064,\n",
       " 0.7069840142953734,\n",
       " 0.6600346440462977,\n",
       " 0.7797145979145887,\n",
       " 0.7668101372745519,\n",
       " 0.7791815445701096,\n",
       " 0.7495607763023494,\n",
       " 0.806585128867076,\n",
       " 0.7012325920267097,\n",
       " 0.6793468339114196,\n",
       " 0.7828330505279035,\n",
       " 0.7878660074664515,\n",
       " 0.7843221003931327,\n",
       " 0.771021720586823,\n",
       " 0.8417375684081474,\n",
       " 0.7196817989171314,\n",
       " 0.8084256352432732,\n",
       " 0.7812671152377034,\n",
       " 0.6901089188026308,\n",
       " 0.6964771512246539,\n",
       " 0.6934625187982568,\n",
       " 0.761682728599349,\n",
       " 0.8412495543672014,\n",
       " 0.7834441537617918,\n",
       " 0.8038922088102908,\n",
       " 0.7837825882704179,\n",
       " 0.698110060690943,\n",
       " 0.7175501519975405,\n",
       " 0.7463181769898971,\n",
       " 0.7506122014004275,\n",
       " 0.7711365530300406,\n",
       " 0.7059380700435468,\n",
       " 0.7320188868192835,\n",
       " 0.6448510946441383,\n",
       " 0.7074014608194376,\n",
       " 0.8221832192189098,\n",
       " 0.8016941032823386,\n",
       " 0.6511121721415839,\n",
       " 0.6938496732026144,\n",
       " 0.781223683043536,\n",
       " 0.6856718576106756,\n",
       " 0.7575238493929579,\n",
       " 0.7424290173226435,\n",
       " 0.6989970403255642,\n",
       " 0.8404715142009168,\n",
       " 0.7041486826770205,\n",
       " 0.697901688453159,\n",
       " 0.5987942639585642,\n",
       " 0.7592650230360078,\n",
       " 0.8724226185832424,\n",
       " 0.7354621995088526,\n",
       " 0.8298215122983794,\n",
       " 0.7463959063249124,\n",
       " 0.7638992474154148,\n",
       " 0.754674710047629,\n",
       " 0.7621011574897893,\n",
       " 0.8675058446455506,\n",
       " 0.7438816177812121,\n",
       " 0.74923561563521,\n",
       " 0.6131516979290287,\n",
       " 0.7778048824351543,\n",
       " 0.6641784332915069,\n",
       " 0.7946588155180356,\n",
       " 0.8448515319103553,\n",
       " 0.6427412085588465,\n",
       " 0.7243781708487591,\n",
       " 0.8367286084701815,\n",
       " 0.681618934930294,\n",
       " 0.8253619562289837,\n",
       " 0.6491466792548924,\n",
       " 0.7458690059478074,\n",
       " 0.7125418733853806,\n",
       " 0.7820213903743316,\n",
       " 0.8622250575658283,\n",
       " 0.7239310526075232,\n",
       " 0.8370394849575286,\n",
       " 0.7792415549674152,\n",
       " 0.726222816399287,\n",
       " 0.8196846506688038,\n",
       " 0.6356173271173271,\n",
       " 0.7564826593613357,\n",
       " 0.8627080505279036,\n",
       " 0.6763761711581184,\n",
       " 0.7049245099380749,\n",
       " 0.6205821248694109,\n",
       " 0.7725941444176738,\n",
       " 0.7641174377319297,\n",
       " 0.7061637578108166,\n",
       " 0.7559171889528795,\n",
       " 0.754794344964924,\n",
       " 0.7857486925065669]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
